import zipfile
import json
import inspect
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from itertools import product

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st
import yaml, joblib, pickle

from bokeh.plotting import figure
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \
    RandomForestClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.impute import SimpleImputer
from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, LogisticRegression, Ridge
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, mean_squared_error, precision_score, recall_score, roc_auc_score
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier

from streamlit_card import card
from streamlit_lottie import st_lottie
from streamlit_option_menu import option_menu
from warnings import filterwarnings
from sklearn.exceptions import ConvergenceWarning
import time

filterwarnings('ignore', category=ConvergenceWarning)

def handle_file_upload(uploaded_file):
    try:
        if uploaded_file is None:
            st.error('LÃ¼tfen bir veri seti yÃ¼kleyin. Veri setinizi eÄŸitim ve test iÃ§in hazÄ±rladÄ±ysanÄ±z, bir sonraki adÄ±ma geÃ§in.', icon="ğŸš¨")
        else:
            if uploaded_file.type == 'text/csv':  # CSV dosyasÄ± yÃ¼klenirse
                df = pd.read_csv(uploaded_file)
                st.success("CSV Data loaded successfully. Let's continue with Machine Learning!", icon="âœ…")
            elif uploaded_file.type == 'text/yaml':  # YAML dosyasÄ± yÃ¼klenirse
                    yaml_verisi = yaml.safe_load(uploaded_file)
                    # YAML verisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
                    df = pd.DataFrame(yaml_verisi)
                    # CSV dosyasÄ±na kaydet
                    df.to_csv("veri.csv", index=False)
                    # CSV dosyasÄ±nÄ± tekrar yÃ¼kle
                    df = pd.read_csv("veri.csv")
                    st.success("YAML Data loaded successfully.Let's continue with Machine Learning!", icon="âœ…")
            elif uploaded_file.type == 'application/json':  # JSON dosyasÄ± yÃ¼klenirse
                    json_verisi = json.load(uploaded_file)
                    # JSON verisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
                    df = pd.DataFrame(json_verisi)
                    # CSV dosyasÄ±na kaydet
                    df.to_csv("veri.csv", index=False)
                    # CSV dosyasÄ±nÄ± tekrar yÃ¼kle
                    df = pd.read_csv("veri.csv")
                    st.success("JSON Data loaded successfully.Let's continue with Machine Learning!", icon="âœ…")
            elif uploaded_file.type in ['application/zip', 'application/x-zip-compressed']:  # Zip dosyasÄ± yÃ¼klenirse (resim klasÃ¶rÃ¼)
                    with zipfile.ZipFile(uploaded_file, 'r') as zip_ref:
                        zip_ref.extractall("extracted_images")
                    st.success("ZIP/Image folder has been successfully uploaded and opened.Let's continue with Machine Learning!", icon="âœ…")
            else:
                st.write("The file format is not supported.")
                
            if df.empty:
                    st.error('The loaded data set is empty.', icon="ğŸš¨")
            
            return df
        
    except (pd.errors.EmptyDataError, pd.errors.ParserError):
        st.error("No columns to parse from file. Please check the file content.", icon="ğŸš¨")
    except Exception as e:
        st.error(f"Error reading the file: {e}", icon="ğŸš¨")   

def find_best_params_classification(name, model, X, Y, test_size_range, random_state_range, max_depth_range):
    best_score = float('-inf')
    best_params = {}

    for test_size, random_state, max_depth in product(test_size_range, random_state_range, max_depth_range):
        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)

        model_instance = model

        if hasattr(model_instance, 'random_state'):
            model_instance.set_params(random_state=random_state)
        if hasattr(model_instance, 'max_depth'):
            model_instance.set_params(max_depth=max_depth)

        model_instance.fit(X_train, Y_train)
        Y_pred = model_instance.predict(X_test)
        score = accuracy_score(Y_test, Y_pred)

        if score > best_score:
            best_score = score
            best_params = {'test_size': test_size, 'random_state': random_state, 'max_depth': max_depth}

    return {'name': name, 'best_params': best_params, 'best_score': best_score}

def find_best_params_regression(name, model, X, Y, test_size_range, random_state_range):
    best_score = float('inf')
    best_params = {}

    for test_size, random_state in product(test_size_range, random_state_range):
        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)

        model_instance = model

        if hasattr(model_instance, 'random_state'):
            model_instance.set_params(random_state=random_state)

        model_instance.fit(X_train, Y_train)
        Y_pred = model_instance.predict(X_test)
        score = mean_squared_error(Y_test, Y_pred)

        if score < best_score:
            best_score = score
            best_params = {'test_size': test_size, 'random_state': random_state}

    return {'name': name, 'best_params': best_params, 'best_score': best_score}

def save_model(model, format_choice, filename):
    if format_choice == 'joblib':
        joblib.dump(model, filename)
        st.write(f"Model baÅŸarÄ±yla '{filename}' adlÄ± dosyaya kaydedildi.")
    elif format_choice == 'pickle':
        with open(filename, 'wb') as f:
            pickle.dump(model, f)
        st.write(f"Model baÅŸarÄ±yla '{filename}' adlÄ± dosyaya kaydedildi.")
    elif format_choice == 'onnx':
        st.write("Bu model ONNX formatÄ±nda kaydedilemez.")
    else:
        st.write("GeÃ§ersiz format seÃ§imi! LÃ¼tfen 'joblib', 'pickle', 'h5', 'onnx', 'json' veya 'yaml' ÅŸeklinde bir format seÃ§in.")

def data_preprocessing(df):
    try:
        # Yinelenen satÄ±rlarÄ± kaldÄ±rma
        df.drop_duplicates(inplace=True)
        # Label Encoding iÅŸlemi burada gerÃ§ekleÅŸecek
        label_encoder = LabelEncoder()
        string_columns = df.select_dtypes(include=['object']).columns
        df[string_columns] = df[string_columns].apply(label_encoder.fit_transform)
        # Integer deÄŸerlere ortalama ile eksik deÄŸerleri doldurma
        integer_columns = df.select_dtypes(include=['int', 'float']).columns
        df[integer_columns] = df[integer_columns].fillna(df[integer_columns].mean())
        # String deÄŸerlere "Bilinmiyor" ile eksik deÄŸerleri doldurma
        string_columns = df.select_dtypes(include=['object']).columns
        df[string_columns] = df[string_columns].fillna("Bilinmiyor")
        
        return df, label_encoder
    
    except Exception as e:
        st.write(f"Hata: {e}")
        return None

def predict_new_data(model, columns, label_encoder):
    new_data = {}
    for column in columns:
        value = input(f"{column}: ")
        new_data[column] = [value if not value.replace('.', '', 1).isdigit() else float(value)]

    new_df = pd.DataFrame(new_data)

    # Yeni verilerin dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi
    string_columns = new_df.select_dtypes(include=['object']).columns
    new_df[string_columns] = new_df[string_columns].apply(label_encoder.fit_transform)
    new_df = new_df.reindex(columns=columns, fill_value=0)

    prediction = model.predict(new_df)
    st.write("Tahmin edilen hedef deÄŸiÅŸken:", prediction)

#MAKÄ°NE Ã–ÄRENMESÄ°
def automl(df):
    try:
        if df is None:
            st.error('Please upload a dataset. If your dataset is prepared for training and testing, go to the next step.', icon="ğŸš¨")
            return      
        with st.container(border=True):
            st.info("Ä°ÅŸleminiz bir sÃ¼re devam edecek. Haydi baÅŸlayalÄ±m!", icon='ğŸ‰')
            df, label = data_preprocessing(df)

            # Model seÃ§enekleri ve kÄ±saltmalarÄ±
            classification_models = [
                ("LR", LogisticRegression()),
                ("LDA", LinearDiscriminantAnalysis()),
                ("KNN", KNeighborsClassifier()),
                ("DT", DecisionTreeClassifier()),
                ("NB", GaussianNB()),
                ("SVM", SVC()),
                ("RF", RandomForestClassifier()),
                ("GB", GradientBoostingClassifier()),
                ("XGB", XGBClassifier()),
                ("LGBM", LGBMClassifier()),
                ("CatBoost", CatBoostClassifier()),
                ("MLP", MLPClassifier()),
                ("AdaBoost", AdaBoostClassifier()),
                ("Bagging", BaggingClassifier()),
                ("ExtraTrees", ExtraTreesClassifier()),
                ("GaussianProcess", GaussianProcessClassifier())
            ]
            regression_models = [
                ("LinearRegression", LinearRegression()),
                ("Ridge", Ridge()),
                ("Lasso", Lasso()),
                ("ElasticNet", ElasticNet())
            ]

            # Hedef deÄŸiÅŸkeni seÃ§imi ve problem tÃ¼rÃ¼ seÃ§imi
            problem_type = st.selectbox("Problemin tÃ¼rÃ¼nÃ¼ seÃ§in:", options=['SÄ±nÄ±flandÄ±rma', 'Regresyon'])
            hedef_degisken = st.selectbox("Hedef DeÄŸiÅŸkeni SeÃ§in", df.columns.tolist())
            st.write(problem_type)

            if hedef_degisken in df.columns:
                X = df.drop(hedef_degisken, axis=1)  # BaÄŸÄ±msÄ±z deÄŸiÅŸkenler
                Y = df[hedef_degisken]  # Hedef deÄŸiÅŸken
            else:
                st.write("Hedef deÄŸiÅŸken adÄ± geÃ§ersiz. LÃ¼tfen mevcut bir hedef deÄŸiÅŸken adÄ± girin.")
                return
            
            if problem_type == "SÄ±nÄ±flandÄ±rma":
                all_models = [name for name, _ in classification_models]
                first_model = st.selectbox("Ä°lk modeli seÃ§in:", all_models, index=0)
                second_model = st.selectbox("Ä°kinci modeli seÃ§in:", all_models, index=0)
                selected_models = [first_model, second_model]
                
            else:
                selected_models = ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']

            ml_start = st.button("Makine Ã–ÄŸrenmesini BaÅŸlat.")
            
            if ml_start:
                st.info("Makine Ã¶ÄŸrenmesi baÅŸlatÄ±ldÄ±. LÃ¼tfen sonuÃ§larÄ± bekleyiniz.", icon='ğŸ¤–')

                if problem_type == 'SÄ±nÄ±flandÄ±rma':
                    st.info("SÄ±nÄ±flandÄ±rma yapÄ±lÄ±yor.", icon="â„¹ï¸")
                    models = [model for name, model in classification_models if name in selected_models]
                    find_best_params = find_best_params_classification
                    st.info("SÄ±nÄ±flandÄ±rma best parametreleri bulundu.", icon="â„¹ï¸")
                    
                    test_size_range = [0.1, 0.2, 0.3, 0.4]
                    random_state_range = [42, 2021, 12345]
                    max_depth_range = [3, 5, 7, 9]
                
                elif problem_type == 'Regresyon':
                    st.info("Regresyon yapÄ±lÄ±yor.", icon="â„¹ï¸")
                    models = [model for name, model in regression_models if name in selected_models]
                    find_best_params = find_best_params_regression
                    st.info("Regresyon best parametreleri bulundu. Bekleyiniz.", icon="â„¹ï¸")
                    
                    test_size_range = [0.1, 0.2, 0.3, 0.4]
                    random_state_range = [42, 2021, 12345]
                    max_depth_range = []
                
                futures = []
                if problem_type == 'SÄ±nÄ±flandÄ±rma':
                    with ProcessPoolExecutor() as executor:
                        for name, alg in classification_models:
                            if name in selected_models:
                                futures.append(
                                    executor.submit(find_best_params, name, alg, X, Y, test_size_range, random_state_range, max_depth_range))
                elif problem_type == 'Regresyon':
                    with ProcessPoolExecutor() as executor:
                        for name, alg in regression_models:
                            if name in selected_models:
                                futures.append(
                                    executor.submit(find_best_params, name, alg, X, Y, test_size_range, random_state_range))
                
                results = []
                for future in as_completed(futures):
                    result = future.result()
                    results.append(result)

                df_models = pd.DataFrame({
                    "Models": selected_models,
                    })
                
                # SonuÃ§larÄ± DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rme
                df_results = pd.DataFrame(results)

                #    Streamlit arayÃ¼zÃ¼nde tabloyu gÃ¶sterme
                st.write("SeÃ§ilen Modeller")
                st.write(df_models)
                st.write("SonuÃ§lar")
                st.write(df_results)
       
    except Exception as e:
        st.write(f"Hata: {e}")

def manualml(df):
    if df is None:
        st.error('Please upload a dataset. If your dataset is prepared for training and testing, go to the next step.', icon="ğŸš¨")
        return
    
    st.info("Ä°ÅŸleminiz bir sÃ¼re devam edecek. Haydi baÅŸlayalÄ±m!", icon='ğŸ‰')
    df, Label_Encoder= data_preprocessing(df)  # data_preprocessing fonksiyonu tanÄ±mlanmalÄ± veya bu satÄ±r kaldÄ±rÄ±lmalÄ±

    # KullanÄ±labilir modeller ve bunlarÄ±n adlarÄ±
    models = [
        ("LR", LogisticRegression),
        ("LIR", LinearRegression),
        ("LDA", LinearDiscriminantAnalysis),
        ("KNN", KNeighborsClassifier),
        ("DT", DecisionTreeClassifier),
        ("NB", GaussianNB),
        ("SVM", SVC),
        ("RF", RandomForestClassifier),
        ("GB", GradientBoostingClassifier),
        ("XGB", XGBClassifier),
        ("LGBM", LGBMClassifier),
        ("CatBoost", CatBoostClassifier),
        ("MLP", MLPClassifier),
        ("AdaBoost", AdaBoostClassifier),
        ("Bagging", BaggingClassifier),
        ("ExtraTrees", ExtraTreesClassifier),
        ("GaussianProcess", GaussianProcessClassifier),
        ("Ridge Regression", Ridge),
        ("Lasso Regression", Lasso),
        ("ElasticNet Regresyon", ElasticNet)
    ]

    # X ve y ayrÄ±ÅŸtÄ±rma
    target_variable = st.selectbox("Hedef deÄŸiÅŸkeni seÃ§in:", df.columns)
    X = df.drop(columns=[target_variable])
    y = df[target_variable]

    # KullanÄ±cÄ±dan test_size ve random_state deÄŸerlerini al
    col1, col2, col3 = st.columns(3)
    with col1:
        test_size = st.number_input("Test setinin oranÄ±nÄ± girin (Ã¶rn: 0.2):", min_value=0.1, max_value=0.9, step=0.1, value=0.2)
    with col2:
        random_state = st.number_input("Random state deÄŸerini girin (Ã¶rn: 42):", min_value=0, step=1, value=42)
    with col3:
        # KullanÄ±cÄ±dan model seÃ§mesini iste
        all_models = [name for name, _ in models]
        selected_model_name = st.selectbox("Modelleri SeÃ§in (Maksimum 2)", all_models)
        selected_model_class = [model for name, model in models if name in selected_model_name]

    if len(selected_model_class) == 0:
        st.error("LÃ¼tfen en az bir model seÃ§in.", icon="ğŸš¨")
        return

    selected_model_class = selected_model_class[0]

    # SeÃ§ilen modelin parametrelerini kullanÄ±cÄ±ya gÃ¶ster
    params = {}
    st.write(f"SeÃ§ilen model: {selected_model_name[0]}")
    st.write("Bu modelin alabileceÄŸi parametreler:")
    
    prm_names= []
    prm_def= []
    signature = inspect.signature(selected_model_class)
    for param in signature.parameters.values():
        if param.name != 'self':
            prm_names.append(str(param.name))
            prm_def.append(str(param.default))

    data = pd.DataFrame({
                "Parameters": [i for i in prm_names],
                "Default Value": [i for i in prm_def]
        })
    
    st.dataframe(data)
    # KullanÄ±cÄ±dan parametreleri al
    selected_params = []
    
    params = {}

    selected_values = st.multiselect("Parametreleri seÃ§in:", prm_names, key="multiselect")
    mm =''
    value = None  # BaÅŸlangÄ±Ã§ta None deÄŸeri atanÄ±yor

    # After getting all the parameters, prompt the user to input their values
    value = None  # BaÅŸlangÄ±Ã§ta None deÄŸeri atanÄ±yor
    if len(selected_values) > 0:
        value = st.text_input(f"{selected_values} iÃ§in  sÄ±rasÄ±yla boÅŸluk bÄ±rakarak deÄŸer gir:")
    value_list = []
    if st.button("Params are ready."):
        value_list = value.split()
    
    # Her bir Ã¶ÄŸeyi uygun tÃ¼rde bir deÄŸere dÃ¶nÃ¼ÅŸtÃ¼r
    converted_values = []
    for val in value_list:
        if val.lower() == "true":
            converted_values.append(True)
        elif val.lower() == "false":
            converted_values.append(False)
        else:
            try:
                converted_values.append(float(val))
            except ValueError:
                converted_values.append(val)  # Hata durumunda aynÄ± deÄŸeri kullan

    print(converted_values)

    params = dict(zip(selected_values, converted_values))
    st.write(params)
    # Modeli parametrelerle oluÅŸtur
    model = selected_model_class(**params)
    st.write(model)
    
    # Veriyi eÄŸitim ve test setine ayÄ±r
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # Modeli eÄŸit ve test et
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Modelin parametrelerini yazdÄ±rma
    #st.write("Model Parametreleri:", model.get_params())
    # SonuÃ§larÄ± deÄŸerlendir
    if selected_model_name[0] in ["LIR", "Ridge Regression", "Lasso Regression", "ElasticNet Regresyon"]:
        # Regresyon modelleri iÃ§in
        mse = mean_squared_error(y_test, y_pred)
        st.write("Mean Squared Error:", mse)
    else:
        # SÄ±nÄ±flandÄ±rma modelleri iÃ§in
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
        

        # SonuÃ§larÄ± yazdÄ±rma
        st.write("Accuracy:", accuracy)
        st.write("Precision:", precision)
        st.write("Recall:", recall)
        st.write("F1 Score:", f1)
    
    # Modeli kaydetme
    save_choice = st.selectbox("Modeli kaydetmek ister misiniz?:", ["Evet", "HayÄ±r"])
    if save_choice== "Evet":
        format_choice = st.selectbox("LÃ¼tfen kaydetmek istediÄŸiniz dosya formatÄ±nÄ± seÃ§in:", ["joblib", "pickle", "onnx"])
        if format_choice == "joblib":
            # Modeli joblib ile dosyaya kaydetme
            joblib.dump(model, "model_ATOMai.pkl")

            # DosyayÄ± Streamlit ile indirme dÃ¼ÄŸmesine baÄŸlama
            st.download_button("Modeli Ä°ndir", "model_ATOMai.pkl", "Ä°ndir")
            #st.download_button("Download some text", joblib.dump(model, "model_ATOMai"))
        elif format_choice == "pickle":
            with open("model_ATOMai", 'wb') as f:
                st.download_button("Download some text", pickle.dump(model, f))
        elif format_choice == "onnx":
            text_contents = "text dosyasÄ±dÄ±r"
            st.download_button("Download some text", text_contents)
            
        #filename = input("Kaydetmek istediÄŸiniz dosyanÄ±n adÄ±nÄ± girin (Ã¶rn: model.pkl, model.h5, model.onnx, model.json, model.yaml): ")
        #save_model(model, format_choice, filename)
    else:
        st.write("Makine Ã–ÄŸrenmesi sonlanmÄ±ÅŸtÄ±r.")

    # Yeni veri ile tahmin yapma
    predict_new_data(model, X.columns, Label_Encoder)
    

# FRONTEND
def frontend():
    st.subheader("Machine Learning")
    st.write("Automates data cleaning and allows the user to perform basic pre-processing steps such as Label Encoding or One-Hot Encoding. Model Selection and Training: By presenting multiple machine learning models to the user, it evaluates the performance of each with different parameters and gives the user the chance to choose the best performing model.")
    with st.expander("ğŸ”— Machine Learning"):
        st.write("Veri iÅŸleme ve model seÃ§imi iÅŸlemlerini otomatikleÅŸtirmek iÃ§in bu aracÄ± kullanabilirsiniz.")
        st.info('If you want to know more in detail, read our [**manual**](https://www.retmon.com/blog/veri-gorsellestirme-nedir#:~:text=Veri%20g%C3%B6rselle%C5%9Ftirme%3B%20verileri%20insan%20beyninin,i%C3%A7in%20kullan%C4%B1lan%20teknikleri%20ifade%20eder.).', icon="â„¹ï¸")
   
    # Dosya yÃ¼kleme iÅŸlemi iÃ§in Streamlit'in file_uploader fonksiyonunu kullanma
    uploaded_file = st.file_uploader("Upload a file", type=["csv", "yaml", "json", "zip"])

    ml_option = st.selectbox("Do you want to do your training yourself or should it be done automatically?", ["Choose", "I'll do it myself.", "Do it."])

    if uploaded_file is None:
        st.error('Please upload a dataset. If your dataset is prepared for training and testing, go to the next step.', icon="ğŸš¨")
    elif ml_option == "I'll do it myself.":
        df = handle_file_upload(uploaded_file)
        manualml(df)
    elif ml_option == "Do it.":
        df = handle_file_upload(uploaded_file)
        automl(df)
    else:
        st.write("Please made an valid selection.")

if __name__ == "__main__":
    # Page configuration
    st.set_page_config(page_title="ATOM AI", layout="wide",)
    # YakÄ±nsama uyarÄ±larÄ±nÄ± bastÄ±rmak iÃ§in ayarlarÄ± yapÄ±landÄ±rma
    filterwarnings("ignore", category=ConvergenceWarning)

    #Frontend ile arayÃ¼zÃ¼n oluÅŸturulmasÄ±.
    frontend()
