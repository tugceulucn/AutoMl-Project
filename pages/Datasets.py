import streamlit as st
from streamlit_option_menu import option_menu
from streamlit_card import card
from streamlit_lottie import st_lottie  # pip install streamlit-lottie
import pandas as pd
import yaml, json, requests
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
import base64

# Sayfa adÄ±nÄ± ve sayfanÄ±n geniÅŸ olmasÄ±nÄ± saÄŸlama
st.set_page_config(
    page_title="ATOM AI",
    layout="wide",
    initial_sidebar_state="expanded"

)

#Animasyon ekleme
def load_lottiefile(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        return json.load(f)

#Loading animasyonu
lottie_coding = load_lottiefile("media/lottieFiles/loading.json")  # replace link to local lottie file

#Temizlenen dosyasÄ± indirme
def convert_df(df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv().encode("utf-8")

#Sekme 1 fonksiyonu: Ä°lk ve son 10 satÄ±rÄ± gÃ¶sterir.
def row_of_datasets(df):
        st.write("**First 10 Rows**")
        st.write(df.head(10))  # Ä°lk 10 satÄ±rÄ± gÃ¶sterme
        st.write("**Last 10 Rows**")
        st.write(df.tail(10))  # Son 10 satÄ±rÄ± gÃ¶sterme

#Sekme 2: SayÄ±sal ve genel bilgileri tablolar aracÄ±lÄ±ÄŸÄ±yla gÃ¶sterir.
def information(df):
        st.caption("The table below shows the number of rows, columns, empty columns and column names of the dataset.The table below shows the number of rows, columns, empty columns and column names of the dataset.The table below shows the number of rows, columns, empty columns and column names of the dataset.The table below shows the number of rows, columns, empty columns and column names of the dataset.")
        #SatÄ±r ve sÃ¼tun sayÄ±sÄ±, sÃ¼tun isimleri ve boÅŸ hÃ¼cre sayÄ±sÄ±nÄ± gÃ¶sterir.
        data = pd.DataFrame({
                        "Information": ["Row", "Columns", "Column Names", "Empty Values"],
                        "Value": [df.shape[0], df.shape[1], df.columns.tolist(), df.isnull().sum().sum() ]
                })
        st.dataframe(data)

        #SÃ¼tunlarÄ±n tÃ¼rlerini gÃ¶rme ve beÅŸ satÄ±r Ã¶rnek gÃ¶sterme
        col1, col2 = st.columns([0.4, 0.6])
        with col1:
                st.write("**Data Types of Columns**")
                st.write(df.dtypes)
        with col2: 
                st.write("**From which column would you like to see sample values?**")
                hel = st.selectbox("Column Names:", df.columns.tolist())
                st.write(df[hel].iloc[:5])
        try:
                st.write("**Statistics of Categorical Columns**")
                st.write(df.describe(include=['O']))
        except: 
                st.info('No categorical data available.', icon="â„¹ï¸")

        
        try:
                st.write("**Statistics of Numerical Columns**")
                st.write(df.describe())
        except:
                st.info('No numerical data available.', icon="â„¹ï¸")

def prepare_data(df, operation, deleted, missing):
    op = ["Remove Duplicate Rows", #Yinelenen satÄ±rlarÄ± kaldÄ±rma 
                                      "Lowercase Column Names",  #SÃ¼tun isimlerini kÃ¼Ã§Ã¼k harfe Ã§evirme
                                      "Lowercase Values in Object Data," #Kategorik verileri kÃ¼Ã§Ã¼k harfe Ã§evirme
                                      "Delete Unnecessary Columns", #Gereksiz kolonlarÄ± silme
                                      "Fill Missing Values with -Unknown- in String Values", 
                                      "Label Encoding", 
                                      "One-Hot Encoding", 
                                      "Fill Missing Values in Selected Columns"]
    islemler = []
    st.write("YapÄ±lacak iÅŸlemler", operation)
    newdata = df
    
    if op[0] in operations: 
        # Yinelenen satÄ±rlarÄ± kaldÄ±rma
        newdata.drop_duplicates(inplace=True)
        islemler.append("Yinelenen satÄ±rlar silindi.")

    if op[1] in operations: 
        # SÃ¼tun adlarÄ±nÄ± kÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rme
        newdata.columns = [kolon.lower() for kolon in newdata.columns]
        islemler.append("SÃ¼tun isimleri kÃ¼Ã§Ã¼k harfe Ã§evirdi.")

    if op[2] in operations: 
        # Sadece object veri tipinde olan sÃ¼tunlardaki deÄŸerleri kÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rme
        object_columns = newdata.select_dtypes(include=['object']).columns
        newdata[object_columns] = newdata[object_columns].apply(lambda x: x.astype(str).str.lower())
        islemler.append("Object veri tipinde olan sÃ¼tunlardaki deÄŸerleri kÃ¼Ã§Ã¼k harfe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.")

    if op[3] in operations: 
        # Gereksiz kolonlarÄ± silme
        newdata = newdata.drop(columns=deleted)
        islemler.append("Kolonlar silindi.")
        
    if op[4] in operations: 
        # String deÄŸerlere "Bilinmiyor" ile eksik deÄŸerleri doldurma
        string_columns = newdata.select_dtypes(include=['object']).columns
        newdata[string_columns] = newdata[string_columns].fillna("Unknown")
        islemler.append("String deÄŸerlere 'Bilinmiyor' ile eksik deÄŸerleri doldurma")

    if op[5] in operations: 
            # Label Encoding iÅŸlemi burada gerÃ§ekleÅŸecek
            label_encoder = LabelEncoder()
            string_columns = newdata.select_dtypes(include=['object']).columns
            newdata[string_columns] = newdata[string_columns].apply(label_encoder.fit_transform)
            islemler.append("Label Encoding iÅŸlemi tamamlandÄ±.")
           
    if op[6] in operations:
            # One-Hot Encoding iÅŸlemi burada yapÄ±lacak
            newdata = pd.get_dummies(df)
            islemler.append("One-Hot Encoding iÅŸlemi tamamlandÄ±.")
 
    if op[7] in operations:
        # Eksik deÄŸerlere sahip sÃ¼tunlarÄ± bulma
        sutunlar_eksik_deger = newdata.columns[df.isnull().any()].tolist()

        # EÄŸer eksik deÄŸer iÃ§eren bir sÃ¼tun yoksa
        if not sutunlar_eksik_deger:
                st.write("Veri setinde eksik deÄŸer iÃ§eren sÃ¼tun bulunmuyor.")
        else:
                while True:
                        secim = st.multiselect("Eksik deÄŸerleri doldurmak istediÄŸiniz kolon isimleri", df.columns.tolist())
                        
                        if secim is not None:
                                secilen_sutunlar = secim
                                # KullanÄ±cÄ±nÄ±n girdiÄŸi sÃ¼tunlarÄ±n doÄŸruluÄŸunu kontrol etme
                                hatali_sutunlar = [s for s in secilen_sutunlar if s not in newdata.columns]
                                if hatali_sutunlar:
                                        print(f"GeÃ§ersiz sÃ¼tunlar: {', '.join(hatali_sutunlar)}")
                                else:
                                        break
    
                # Eksik deÄŸerlere sahip sÃ¼tunlarÄ± bulma
                sutunlar_eksik_deger = df.columns[df.isnull().any()].tolist()

                # EÄŸer eksik deÄŸer iÃ§eren bir sÃ¼tun yoksa
                if not sutunlar_eksik_deger:
                        print("Veri setinde eksik deÄŸer iÃ§eren sÃ¼tun bulunmuyor.")
                else:
                        while True:
                                secim = missing
                                # SeÃ§ilen sÃ¼tunlardaki eksik deÄŸerleri doldurma iÅŸlemi
                                for kolon in secim:
                                        if newdata[kolon].isnull().any():
                                                if newdata[kolon].dtype in ['int64', 'float64']:
                                                        imputer = SimpleImputer(strategy='mean')
                                                        newdata[[kolon]] = imputer.fit_transform(df[[kolon]])
                                                        st.write(f"{kolon} sÃ¼tunundaki eksik deÄŸerler ortalama ile dolduruldu.")
                                                else:
                                                        st.write(f"{kolon} sÃ¼tunu sayÄ±sal bir veri tipine sahip deÄŸil, eksik deÄŸerler doldurulmadÄ±.")

    # Veri setini CSV formatÄ±nda indirme iÅŸlemi
    csv = convert_df(newdata)
    st.download_button(
        label="Download Data",
        data=csv,
        file_name="updatedDataset.csv",
        mime="text/csv",
     )
    
    st.write(islemler)

    

        
# FRONTEND
st.header("Data Set Cleaning and Editing")
st.write("Automates data cleaning steps such as filling in missing data and deleting unnecessary columns. It also allows the user to perform basic pre-processing steps such as Label Encoding or One-Hot Encoding. Model Selection and Training: By presenting multiple machine learning models to the user, it evaluates the performance of each with different parameters and gives the user the chance to choose the best performing model.")
with st.expander("ğŸ”— Data Analysis"):
        st.write("Bir ÅŸirket, karar vermeBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§in sÃ¼recini ÅŸekillendirmek iÃ§in verileri kullanÄ±rken alakalÄ±, eksiksiz ve doÄŸru verileri kullanmalarÄ± Ã§ok Ã¶nemlidir. Bununla birlikte, veri kÃ¼meleri genellikle analizden Ã¶nce ortadan kaldÄ±rÄ±lmasÄ± gereken hatalar iÃ§erir. Bu hatalar, tahminleri Ã¶nemli Ã¶lÃ§Ã¼de etkileyebilecek yanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ tarihler, parasal deÄŸerler ve diÄŸer Ã¶lÃ§Ã¼m birimleri gibi biÃ§imlendirme hatalarÄ±nÄ± iÃ§erebilir. AykÄ±rÄ± deÄŸerler, sonuÃ§larÄ± her durumda Ã§arpÄ±ttÄ±ÄŸÄ±ndan Ã¶nemli bir endiÅŸe kaynaÄŸÄ±dÄ±r. YaygÄ±n olarak bulunan diÄŸer veri hatalarÄ±; bozuk veri noktalarÄ±nÄ±, eksik bilgileri ve yazÄ±m hatalarÄ±nÄ± iÃ§erir. Temiz veriler, ML modellerinin yÃ¼ksek oranda doÄŸru olmasÄ±na yardÄ±mcÄ± olabilir. DÃ¼ÅŸÃ¼k kaliteli eÄŸitim veri kÃ¼melerini kullanmak, daÄŸÄ±tÄ±lan modellerde hatalÄ± tahminlere neden olabileceÄŸinden temiz ve doÄŸru veriler, makine Ã¶ÄŸrenimi modellerini eÄŸitmek iÃ§in Ã¶zellikle Ã¶nemlidir. Veri bilimcilerinin, zamanlarÄ±nÄ±n bÃ¼yÃ¼k bir kÄ±smÄ±nÄ± makine Ã¶ÄŸrenimi iÃ§in veri hazÄ±rlamaya ayÄ±rmalarÄ±nÄ±n baÅŸlÄ±ca nedeni budur.")

with st.expander("ğŸ”— Data Cleaning"):
        st.write("Bir ÅŸirket, karar vermeBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§inBir ÅŸirket, karar verme sÃ¼recini ÅŸekillendirmek iÃ§in sÃ¼recini ÅŸekillendirmek iÃ§in verileri kullanÄ±rken alakalÄ±, eksiksiz ve doÄŸru verileri kullanmalarÄ± Ã§ok Ã¶nemlidir. Bununla birlikte, veri kÃ¼meleri genellikle analizden Ã¶nce ortadan kaldÄ±rÄ±lmasÄ± gereken hatalar iÃ§erir. Bu hatalar, tahminleri Ã¶nemli Ã¶lÃ§Ã¼de etkileyebilecek yanlÄ±ÅŸ yazÄ±lmÄ±ÅŸ tarihler, parasal deÄŸerler ve diÄŸer Ã¶lÃ§Ã¼m birimleri gibi biÃ§imlendirme hatalarÄ±nÄ± iÃ§erebilir. AykÄ±rÄ± deÄŸerler, sonuÃ§larÄ± her durumda Ã§arpÄ±ttÄ±ÄŸÄ±ndan Ã¶nemli bir endiÅŸe kaynaÄŸÄ±dÄ±r. YaygÄ±n olarak bulunan diÄŸer veri hatalarÄ±; bozuk veri noktalarÄ±nÄ±, eksik bilgileri ve yazÄ±m hatalarÄ±nÄ± iÃ§erir. Temiz veriler, ML modellerinin yÃ¼ksek oranda doÄŸru olmasÄ±na yardÄ±mcÄ± olabilir. DÃ¼ÅŸÃ¼k kaliteli eÄŸitim veri kÃ¼melerini kullanmak, daÄŸÄ±tÄ±lan modellerde hatalÄ± tahminlere neden olabileceÄŸinden temiz ve doÄŸru veriler, makine Ã¶ÄŸrenimi modellerini eÄŸitmek iÃ§in Ã¶zellikle Ã¶nemlidir. Veri bilimcilerinin, zamanlarÄ±nÄ±n bÃ¼yÃ¼k bir kÄ±smÄ±nÄ± makine Ã¶ÄŸrenimi iÃ§in veri hazÄ±rlamaya ayÄ±rmalarÄ±nÄ±n baÅŸlÄ±ca nedeni budur.")

st.info('If you want to know more in detail, read our [**manual**](https://www.retmon.com/blog/veri-gorsellestirme-nedir#:~:text=Veri%20g%C3%B6rselle%C5%9Ftirme%3B%20verileri%20insan%20beyninin,i%C3%A7in%20kullan%C4%B1lan%20teknikleri%20ifade%20eder.).', icon="â„¹ï¸")

# Dosya yÃ¼kleme iÅŸlemi iÃ§in Streamlit'in file_uploader fonksiyonunu kullanma
uploaded_file = st.file_uploader("Upload a file", type=["csv", "yaml", "json", "jpg", "png"])

st.caption("Automates data cleaning steps such as filling in missing data and deleting unnecessary columns. It also allows the user to perform basic pre-processing steps such as Label Encoding or One-Hot Encoding. Model Selection and Training: By presenting multiple machine learning models to the user, it evaluates the performance of each with different parameters and gives the user the chance to choose the best performing model.")

#Dosya tÃ¼rÃ¼nÃ¼ analiz eder ve dosya tÃ¼rÃ¼ json veya yaml ise csv dosyasÄ±na Ã§evirir.
#Analiz ve temizleme iÅŸlemleri sekmeli sayfada yapÄ±lÄ±r.
tab1, tab2, tab3, tab4 = st.tabs(["Dataset", "Information", "Graphics", "Cleaning"])
                      
with tab1:
        try:
                if uploaded_file is None:
                        st.error('LÃ¼tfen bir veri seti yÃ¼kleyin. Veri setinizi eÄŸitim ve test iÃ§in hazÄ±rladÄ±ysanÄ±z, bir sonraki adÄ±ma geÃ§in.', icon="ğŸš¨")
                elif uploaded_file.type == 'text/csv':  # CSV dosyasÄ± yÃ¼klenirse
                        df = pd.read_csv(uploaded_file)
                        if df.empty:
                                st.error('YÃ¼klenen veri seti boÅŸ.', icon="ğŸš¨")
                                df = pd.read_csv(uploaded_file)
                        else:
                                row_of_datasets(df)

                elif uploaded_file.type == 'text/yaml': # YAML dosyasÄ± yÃ¼klenirse
                        yaml_verisi = yaml.safe_load(uploaded_file)
                        # YAML verisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
                        df = pd.DataFrame(yaml_verisi)
                        # CSV dosyasÄ±na kaydet
                        df.to_csv("veri.csv", index=False)
                        df = "veri.csv"
                elif uploaded_file.type == 'text/json':  # Json dosyasÄ± yÃ¼klenirse
                        json_verisi = json.load(uploaded_file)
                        # JSON verisini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
                        df = pd.DataFrame(json_verisi)
                        # CSV dosyasÄ±na kaydet
                        df.to_csv("veri.csv", index=False)        
                else:
                        st.write("Dosya formatÄ± desteklenmiyor.")

        except (pd.errors.EmptyDataError, pd.errors.ParserError):

                st.error('YÃ¼klenen veri seti boÅŸ veya geÃ§ersiz.', icon="ğŸš¨")
        except Exception as e:
                st.error(f'Bir hata oluÅŸtu: {e}', icon="ğŸš¨")



with tab2:
        try:
                if uploaded_file is None:
                        st.error('Please upload a dataset. If your dataset prepare for train and testing, go to next  step.', icon="ğŸš¨")
                
                else:
                        if df.empty:
                                st.error('The uploaded dataset is empty.', icon="ğŸš¨")
                        else:
                                information(df)
        except (pd.errors.EmptyDataError, pd.errors.ParserError):
                st.error('YÃ¼klenen veri seti boÅŸ veya geÃ§ersiz.', icon="ğŸš¨")
        except Exception as e:
                st.error(f'Bir hata oluÅŸtu: {e}', icon="ğŸš¨")


with tab3:
        try:
                if uploaded_file is None:
                        st.error('Please upload a dataset. If your dataset prepare for train and testing, go to next  step.', icon="ğŸš¨")
                else:
                        gr = st.selectbox("Hangi grafiÄŸi gÃ¶rÃ¼ntÃ¼lemek istiyorsun?", ["Line Chart", "Bar Chart", "Area Chart", "Scatter Chart"])
                        column_c = st.multiselect("GrafiÄŸe dÃ¶nÃ¼ÅŸtÃ¼rmek istediÄŸiniz sÃ¼tunlarÄ± seÃ§in.", df.columns.tolist() )
                        if gr == "Line Chart":
                                st.caption("Line chart, verilerin bir Ã§izgi grafiÄŸi Ã¼zerinde gÃ¶sterildiÄŸi bir grafik tÃ¼rÃ¼dÃ¼r. X ekseni genellikle zaman veya kategorik deÄŸerlerle iliÅŸkilendirilirken, Y ekseni ise bu deÄŸerlerin karÅŸÄ±lÄ±k geldiÄŸi Ã¶lÃ§Ã¼lebilir verileri temsil eder. Her veri noktasÄ±, X ekseni boyunca konumlandÄ±rÄ±lÄ±r ve belirli bir Y ekseni deÄŸerine sahiptir. Bu noktalar, birbirlerine doÄŸrusal olarak baÄŸlanarak bir Ã§izgi oluÅŸturulur. Line chart, veri setindeki deÄŸiÅŸiklikleri izlemek, trendleri analiz etmek ve iliÅŸkileri anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle zaman serileri verileriyle Ã§alÄ±ÅŸÄ±rken, belirli bir zaman aralÄ±ÄŸÄ±ndaki deÄŸiÅŸimleri anlamak iÃ§in line chart Ã§ok kullanÄ±ÅŸlÄ±dÄ±r.")
                                chart_data = pd.DataFrame(np.random.randn(20, len(column_c)), columns=column_c)
                                st.line_chart(chart_data)
                        elif gr == "Bar Chart":
                                st.caption("Line chart, verilerin bir Ã§izgi grafiÄŸi Ã¼zerinde gÃ¶sterildiÄŸi bir grafik tÃ¼rÃ¼dÃ¼r. X ekseni genellikle zaman veya kategorik deÄŸerlerle iliÅŸkilendirilirken, Y ekseni ise bu deÄŸerlerin karÅŸÄ±lÄ±k geldiÄŸi Ã¶lÃ§Ã¼lebilir verileri temsil eder. Her veri noktasÄ±, X ekseni boyunca konumlandÄ±rÄ±lÄ±r ve belirli bir Y ekseni deÄŸerine sahiptir. Bu noktalar, birbirlerine doÄŸrusal olarak baÄŸlanarak bir Ã§izgi oluÅŸturulur. Line chart, veri setindeki deÄŸiÅŸiklikleri izlemek, trendleri analiz etmek ve iliÅŸkileri anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle zaman serileri verileriyle Ã§alÄ±ÅŸÄ±rken, belirli bir zaman aralÄ±ÄŸÄ±ndaki deÄŸiÅŸimleri anlamak iÃ§in line chart Ã§ok kullanÄ±ÅŸlÄ±dÄ±r.")
                                chart_data = pd.DataFrame(np.random.randn(30, len(column_c)), columns=column_c)
                                st.bar_chart(chart_data)
                        elif gr == "Area Chart":
                                st.caption("Line chart, verilerin bir Ã§izgi grafiÄŸi Ã¼zerinde gÃ¶sterildiÄŸi bir grafik tÃ¼rÃ¼dÃ¼r. X ekseni genellikle zaman veya kategorik deÄŸerlerle iliÅŸkilendirilirken, Y ekseni ise bu deÄŸerlerin karÅŸÄ±lÄ±k geldiÄŸi Ã¶lÃ§Ã¼lebilir verileri temsil eder. Her veri noktasÄ±, X ekseni boyunca konumlandÄ±rÄ±lÄ±r ve belirli bir Y ekseni deÄŸerine sahiptir. Bu noktalar, birbirlerine doÄŸrusal olarak baÄŸlanarak bir Ã§izgi oluÅŸturulur. Line chart, veri setindeki deÄŸiÅŸiklikleri izlemek, trendleri analiz etmek ve iliÅŸkileri anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle zaman serileri verileriyle Ã§alÄ±ÅŸÄ±rken, belirli bir zaman aralÄ±ÄŸÄ±ndaki deÄŸiÅŸimleri anlamak iÃ§in line chart Ã§ok kullanÄ±ÅŸlÄ±dÄ±r.")
                                chart_data = pd.DataFrame(np.random.randn(20, len(column_c)), columns=column_c)
                                st.area_chart(chart_data)
                        elif gr == "Scatter Chart":
                                st.caption("Line chart, verilerin bir Ã§izgi grafiÄŸi Ã¼zerinde gÃ¶sterildiÄŸi bir grafik tÃ¼rÃ¼dÃ¼r. X ekseni genellikle zaman veya kategorik deÄŸerlerle iliÅŸkilendirilirken, Y ekseni ise bu deÄŸerlerin karÅŸÄ±lÄ±k geldiÄŸi Ã¶lÃ§Ã¼lebilir verileri temsil eder. Her veri noktasÄ±, X ekseni boyunca konumlandÄ±rÄ±lÄ±r ve belirli bir Y ekseni deÄŸerine sahiptir. Bu noktalar, birbirlerine doÄŸrusal olarak baÄŸlanarak bir Ã§izgi oluÅŸturulur. Line chart, veri setindeki deÄŸiÅŸiklikleri izlemek, trendleri analiz etmek ve iliÅŸkileri anlamak iÃ§in kullanÄ±lÄ±r. Ã–zellikle zaman serileri verileriyle Ã§alÄ±ÅŸÄ±rken, belirli bir zaman aralÄ±ÄŸÄ±ndaki deÄŸiÅŸimleri anlamak iÃ§in line chart Ã§ok kullanÄ±ÅŸlÄ±dÄ±r.")
                                chart_data = pd.DataFrame(np.random.randn(30, len(column_c)), columns=column_c)
                                st.scatter_chart(chart_data)
                        else:
                                pass
        except (pd.errors.EmptyDataError, pd.errors.ParserError):
                st.error('YÃ¼klenen veri seti boÅŸ veya geÃ§ersiz.', icon="ğŸš¨")
        except Exception as e:
                st.error(f'Bir hata oluÅŸtu: {e}', icon="ğŸš¨")
        
    
with tab4:
        try:
                if uploaded_file is None:
                        st.error('Please upload a dataset. If your dataset prepare for train and testing, go to next  step.', icon="ğŸš¨")
                else:
                        delete_columns = []
                        missing_columns = []
                        op = ["Remove Duplicate Rows", #Yinelenen satÄ±rlarÄ± kaldÄ±rma 
                                      "Lowercase Column Names",  #SÃ¼tun isimlerini kÃ¼Ã§Ã¼k harfe Ã§evirme
                                      "Lowercase Values in Object Data," #Kategorik verileri kÃ¼Ã§Ã¼k harfe Ã§evirme
                                      "Delete Unnecessary Columns", #Gereksiz kolonlarÄ± silme
                                      "Fill Missing Values with -Unknown- in String Values", 
                                      "Label Encoding", 
                                      "One-Hot Encoding", 
                                      "Fill Missing Values in Selected Columns"]
                        
                        operations = st.multiselect("Choose cleaning operations:", op)
                        if "Delete Unnecessary Columns" in operations:
                                delete_columns = st.multiselect("Silinmesini istediÄŸiniz sÃ¼tunlarÄ± seÃ§in: ", df.columns.tolist())
                        if "Find Columns with Missing Values" in operations:
                                missing_columns = st.multiselect("Eksik deÄŸerleri doldurmak istediÄŸiniz kolon isimleri", df.columns.tolist())

                        clean_btn = st.button("Clean the Dataset", type="primary", use_container_width=True) 
                        if clean_btn:
                                prepare_data(df, operations, delete_columns, missing_columns)
        except (pd.errors.EmptyDataError, pd.errors.ParserError):
                st.error('YÃ¼klenen veri seti boÅŸ veya geÃ§ersiz.', icon="ğŸš¨")
        except Exception as e:
                st.error(f'Bir hata oluÅŸtu: {e}', icon="ğŸš¨")
                        



        